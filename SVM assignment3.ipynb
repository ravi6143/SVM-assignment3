{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b28e03-fa1a-4bdf-8045-41c96fb78f94",
   "metadata": {},
   "source": [
    "\n",
    "## Question - 1\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a118ee-1d33-48cf-9898-9b989d91fc88",
   "metadata": {},
   "source": [
    "The RMSE provides a measure of the average magnitude of errors in the predicted house prices, and it is in the same unit as the target variable (price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807fa5f4-86ff-48a0-9c28-044e1c13ce85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e692a5-a8c6-47c6-8052-0f0111a2e71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8da11f1-aa7e-47b0-a217-b418dc501913",
   "metadata": {},
   "source": [
    "## Question - 2\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a46a1e-b9c9-4fac-b527-4439cddaf08d",
   "metadata": {},
   "source": [
    "If  goal is to predict the actual price of a house as accurately as possible, the more appropriate metric to use for evaluation would be the Mean Squared Error (MSE).\n",
    "\n",
    "Here's why:\n",
    "\n",
    "Mean Squared Error (MSE):\n",
    "\n",
    "MSE measures the average squared difference between the predicted and actual values. It penalizes larger errors more heavily.\n",
    "Minimizing MSE implies minimizing the average squared deviation of your predictions from the true prices.\n",
    "For predicting house prices, you typically want to minimize the impact of larger errors, as they can have a significant impact on the overall accuracy of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef998a-a994-463f-bd80-37deaa206d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723f276-e5c3-4954-9012-c2a768eeb691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f51133fc-df44-42b2-a157-b367034e8912",
   "metadata": {},
   "source": [
    "## Question - 3\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f3c1d-9984-4765-9d69-32cc6b35daa9",
   "metadata": {},
   "source": [
    "In a scenario where you have a dataset with a significant number of outliers, the most appropriate regression metric to use with your SVM model is the Mean Absolute Error (MAE).\n",
    "\n",
    "Here's why MAE is often preferred when dealing with datasets containing outliers:\n",
    "\n",
    "1. Robustness to Outliers:\n",
    "\n",
    "MAE is less sensitive to extreme values (outliers) compared to other metrics such as Mean Squared Error (MSE).\n",
    "While MSE squares the errors, giving higher weight to larger errors, MAE treats all errors equally.\n",
    "\n",
    "\n",
    "2. Interpretability:\n",
    "\n",
    "MAE provides a straightforward interpretation as the average absolute difference between predicted and actual values.\n",
    "The impact of each observation on MAE is proportional to the absolute size of the error, making it less influenced by outliers.\n",
    "\n",
    "\n",
    "3. Mean Squared Error (MSE) Pitfall:\n",
    "\n",
    "MSE tends to be influenced more by outliers because it squares the errors. If there are substantial outliers in the dataset, MSE may be disproportionately affected, leading to an inaccurate reflection of the model's overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a298b-9090-474f-a62d-a3211143901f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69238920-39c0-49e4-b3c1-aa4f6a9deb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c288074-0c85-4469-935e-a603f01c59c8",
   "metadata": {},
   "source": [
    "## Question- 4\n",
    "ans-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c435c76-6f86-4b21-92dd-2a75426c0ec5",
   "metadata": {},
   "source": [
    "In the scenario described, where both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are very close, and there is no specific preference or requirement, it is generally reasonable to choose Root Mean Squared Error (RMSE).\n",
    "\n",
    "Here's the rationale:\n",
    "\n",
    "1. Interpretability:\n",
    "\n",
    "RMSE provides a measure of the average magnitude of errors in the same unit as the target variable. This can make it more interpretable, especially when conveying the scale of errors to stakeholders or interpreting the model's performance in the context of the actual values.\n",
    "\n",
    "\n",
    "2. Sensitivity to Outliers:\n",
    "\n",
    "While RMSE gives higher weight to larger errors due to the squaring operation, this can be advantageous if you want the metric to be more sensitive to larger errors, including potential outliers. In scenarios where outliers matter, RMSE might provide a more informative measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580ac3e-c9d1-4875-8f1d-d167f3f49a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf15dc-35f6-466f-9b83-d707130ab42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e44388b-75f7-4d32-bd4b-5578e76f2155",
   "metadata": {},
   "source": [
    "## Question - 5\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad432820-5844-4580-9a70-ae3e6e0c5cf3",
   "metadata": {},
   "source": [
    "If your goal is to measure how well the model explains the variance in the target variable, the most appropriate evaluation metric is the R-squared (R2) score. R-squared is commonly used for this purpose as it quantifies the proportion of the variance in the target variable that is explained by the model.\n",
    "\n",
    "Here's why R-squared is a suitable choice for assessing how well the model explains variance:\n",
    "\n",
    "1. Definition of R-squared:\n",
    "\n",
    "R-squared is a statistical measure that represents the proportion of the variance in the dependent variable (target) that is predictable from the independent variables (features) in the model.\n",
    "It ranges from 0 to 1, with 1 indicating a perfect fit where the model explains all the variance.\n",
    "\n",
    "\n",
    "2. Interpretability:\n",
    "\n",
    "R-squared provides an easily interpretable metric that reflects the goodness of fit of the model.\n",
    "A higher R-squared value indicates that a larger proportion of the variance in the target variable is accounted for by the model.\n",
    "\n",
    "\n",
    "\n",
    "3. Comparison Across Models:\n",
    "\n",
    "R-squared is especially useful when comparing different models with different kernels (linear, polynomial, RBF) as it provides a standardized measure of goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e30cf-e766-432e-bd23-b8cd98163900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b44c3a-faa9-4919-ac48-947886341144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df66d1b-39b8-4669-8f6e-3c15237f6ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
